<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Navigation Assistant</title>
  <style>
    * {
      box-sizing: border-box;
    }

    body, html {
      margin: 0;
      padding: 0;
      height: 100%;
      font-family: Arial, sans-serif;
      background: linear-gradient(135deg, #74ebd5, #9face6);
      display: flex;
      align-items: center;
      justify-content: center;
    }

    .container {
      background: white;
      padding: 25px 20px;
      border-radius: 15px;
      box-shadow: 0 8px 20px rgba(0, 0, 0, 0.15);
      max-width: 100%;
      width: 90%;
      max-width: 500px;
      text-align: center;
    }

    h2 {
      color: #2c3e50;
      margin-bottom: 15px;
    }

    video {
      width: 100%;
      max-width: 100%;
      height: auto;
      border: 4px solid #3498db;
      border-radius: 10px;
      margin-bottom: 15px;
    }

    button {
      padding: 10px 20px;
      font-size: 16px;
      margin: 6px 4px;
      border: none;
      border-radius: 5px;
      cursor: pointer;
      transition: all 0.3s ease;
    }

    #askBtn {
      background-color: #27ae60;
      color: white;
    }

    #askBtn:hover {
      background-color: #1e8449;
    }

    #closeBtn {
      background-color: #c0392b;
      color: white;
      display: none;
    }

    #closeBtn:hover {
      background-color: #96281b;
    }

    #flipBtn {
      background-color: #2980b9;
      color: white;
    }

    #flipBtn:hover {
      background-color: #21618c;
    }

    #output {
      margin-top: 18px;
      font-size: 17px;
      font-weight: bold;
      color: #2d3436;
      min-height: 50px;
    }

    .note {
      font-size: 14px;
      color: #777;
      margin-top: 8px;
    }

    @media (max-width: 500px) {
      button {
        width: 100%;
        margin: 8px 0;
      }

      .container {
        border-radius: 10px;
        padding: 20px 15px;
      }
    }
  </style>
</head>
<body>
  <div class="container">
    <h2>Real-Time AI Navigation Assistant</h2>
    <video id="video" autoplay muted playsinline></video>
    <br />
    <button id="askBtn" onclick="startAskMode()">Ask Q</button>
    <button id="closeBtn" onclick="stopAskMode()">Close Ask</button>
    <button id="flipBtn" onclick="toggleCamera()">ðŸ”„ Flip Camera</button>
    <p class="note">Live guidance with voice and object detection</p>
    <p id="output">Initializing...</p>
  </div>

  <script>
    const video = document.getElementById('video');
    const output = document.getElementById('output');
    let lastMessage = "";
    let isSpeaking = false;
    let askMode = false;
    let recognition;
    let interval;
    let usingBackCamera = true;
    let currentStream;

    function startCamera() {
      const constraints = {
        video: {
          facingMode: usingBackCamera ? { exact: "environment" } : "user"
        },
        audio: false
      };

      navigator.mediaDevices.getUserMedia(constraints)
        .then(stream => {
          if (currentStream) {
            currentStream.getTracks().forEach(track => track.stop());
          }
          currentStream = stream;
          video.srcObject = stream;
          video.onloadedmetadata = () => {
            startGuidanceLoop();
            initVoiceCommands();
          };
        })
        .catch(() => output.textContent = "Camera access denied.");
    }

    function toggleCamera() {
      usingBackCamera = !usingBackCamera;
      stopGuidanceLoop();
      startCamera();
    }

    function startGuidanceLoop() {
      interval = setInterval(() => {
        if (!isSpeaking && !askMode) captureAndAnalyze();
      }, 5000);
    }

    function stopGuidanceLoop() {
      clearInterval(interval);
    }

    function captureAndAnalyze() {
      const canvas = document.createElement('canvas');
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
      canvas.getContext('2d').drawImage(video, 0, 0);
      const image = canvas.toDataURL('image/jpeg');
      output.textContent = "Analyzing...";

      fetch('/analyze', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ image })
      })
      .then(res => res.json())
      .then(data => {
        lastMessage = data.response;
        output.textContent = lastMessage;
        speak(lastMessage);
      });
    }

    function speak(text) {
      isSpeaking = true;
      const utter = new SpeechSynthesisUtterance(text);
      utter.lang = "en-US";
      utter.rate = 1;
      speechSynthesis.cancel();
      speechSynthesis.speak(utter);
      utter.onend = () => isSpeaking = false;
    }

    function startAskMode() {
      askMode = true;
      stopGuidanceLoop();
      document.getElementById("askBtn").style.display = "none";
      document.getElementById("closeBtn").style.display = "inline-block";
      output.textContent = "Listening for your question...";

      const askRecog = new webkitSpeechRecognition();
      askRecog.lang = "en-US";
      askRecog.interimResults = false;
      askRecog.continuous = false;

      askRecog.onresult = e => {
        const question = e.results[0][0].transcript;
        output.textContent = `You asked: ${question}`;
        fetch('/ask', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ query: question })
        })
        .then(res => res.json())
        .then(data => {
          output.textContent = data.response;
          speak(data.response);
        });
      };
      askRecog.start();
    }

    function stopAskMode() {
      askMode = false;
      output.textContent = "Resuming guidance...";
      startGuidanceLoop();
      document.getElementById("askBtn").style.display = "inline-block";
      document.getElementById("closeBtn").style.display = "none";
    }

    function initVoiceCommands() {
      if (!('webkitSpeechRecognition' in window)) return;
      recognition = new webkitSpeechRecognition();
      recognition.lang = 'en-US';
      recognition.continuous = true;
      recognition.onresult = (event) => {
        const transcript = event.results[event.results.length - 1][0].transcript.trim().toLowerCase();
        if (transcript.includes('repeat')) speak(lastMessage);
        else if (transcript.includes('pause')) isSpeaking = true;
        else if (transcript.includes('resume')) isSpeaking = false;
        else if (transcript.includes('what is ahead')) captureAndAnalyze();
      };
      recognition.start();
    }

    // Start camera on load
    window.onload = () => {
      startCamera();
    };
  </script>
</body>
</html>
